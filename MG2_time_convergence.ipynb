{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MG2 Convergence Testing\n",
    "\n",
    "This notebook provides the capability to make temporal convergence plots of the MG2 microphysics. While the testing itself is not fully automated, this notebook produces plots and statistics that make it easier to determine the degree to which MG2 converges at approximately first order.\n",
    "\n",
    "This module requires a few dependencies (listed in the [Import statements](#import-statements) section below), as well as a compatible data file. Such a file should be a history file produced by EAM or CAM, or a netCDF file containing data in the same format (e.g. dimension names and order, same units for variables, and so on). This file should contain all variables used as input to the MG2 microphysics, each in all caps and prefixed with `MG2IN_`. E.g. there will be a `MG2IN_T` variable, an `MG2IN_Q` variable, and so on. Aerosol-related variables `RNDST` and `NACON` have an extra dimension of size four, which is handled using number suffixes rather than by adding a dimension to the netCDF file. E.g. the variables `MG2IN_RNDST1` through `MG2IN_RNDST4` should be present. For a full list of input variables, see the [Initialization](#initialization) code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements<a id=\"import-statements\"></a>\n",
    "\n",
    "Note that in addition to the standard Jupyter dependencies, the netCDF4 python interface is used to run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies of this notebook.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.linalg as la\n",
    "import netCDF4 as nc4\n",
    "\n",
    "# MG2 module (created with f2py)\n",
    "from mg2 import wv_sat_methods as wsm\n",
    "from mg2 import micro_mg2_0 as mg\n",
    "\n",
    "# Module with constants used by MG2\n",
    "# At the time of this writing (2017), these are generally the same as those in E3SM,\n",
    "# except for the precipitation fraction method.\n",
    "from mg2_constants import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization <a id=\"initialization\"></a>\n",
    "\n",
    "Note that the `HIST_FILE_NAME` must point to a properly formatted netCDF data file with the expected inputs. The `mgncol` variable does not affect the results, but can be tuned to generate plots faster. This value represents the number of columns that can be fed into MG2 at once, and generally represents a tradeoff between vectorization (more columns is better, at least up to a point) and effective cache usage (more columns is worse).\n",
    "\n",
    "Note that currently the `total_columns` (see below) must be a multiple of `mgncol`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HIST_FILE_NAME = \"/home/santos/Data/MG2_data_collection.cam.h1.0001-01-06-00000.nc\"\n",
    "mgncol = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = nc4.Dataset(HIST_FILE_NAME, 'r')\n",
    "\n",
    "ncol = len(file.dimensions['ncol'])\n",
    "lev = len(file.dimensions['lev'])\n",
    "ilev = len(file.dimensions['ilev'])\n",
    "\n",
    "errstring = wsm.wv_sat_methods_init(kind, tmelt, h2otrip, tboil, ttrice, epsilo)\n",
    "\n",
    "assert errstring.decode().strip() == '', \\\n",
    "    \"wv_sat_methods initialization error: \"+errstring.decode()\n",
    "\n",
    "errstring = mg.micro_mg_init(kind, gravit, rair, rh2o, cpair, tmelt, latvap,\n",
    "                             latice, rhmini, dcs, dcs_tdep, uniform, do_cldice,\n",
    "                             use_hetfrz_classnuc, precip_frac_method,\n",
    "                             berg_eff_factor, allow_sed_supersat, ice_sed_ai,\n",
    "                             prc_coef1, prc_exp, prc_exp1, cld_sed,\n",
    "                             mg_prc_coeff_fix, alpha_grad, beta_grad)\n",
    "\n",
    "assert errstring.decode().strip() == '', \\\n",
    "    \"MG2 initialization error: \"+errstring.decode()\n",
    "\n",
    "mgncol = 128\n",
    "t = file.variables[\"MG2IN_T\"]\n",
    "q = file.variables[\"MG2IN_Q\"]\n",
    "qc = file.variables[\"MG2IN_QC\"]\n",
    "qi = file.variables[\"MG2IN_QI\"]\n",
    "nc = file.variables[\"MG2IN_NC\"]\n",
    "ni = file.variables[\"MG2IN_NI\"]\n",
    "qr = file.variables[\"MG2IN_QR\"]\n",
    "qs = file.variables[\"MG2IN_QS\"]\n",
    "nr = file.variables[\"MG2IN_NR\"]\n",
    "ns = file.variables[\"MG2IN_NS\"]\n",
    "relvar = file.variables[\"MG2IN_RELVAR\"]\n",
    "accre_enhan = file.variables[\"MG2IN_ACCRE_ENHAN\"]\n",
    "p = file.variables[\"MG2IN_P\"]\n",
    "pdel = file.variables[\"MG2IN_PDEL\"]\n",
    "precipf = file.variables[\"MG2IN_PRECIP\"]\n",
    "liqcldf = file.variables[\"MG2IN_LIQCLDF\"]\n",
    "icecldf = file.variables[\"MG2IN_ICECLDF\"]\n",
    "naai = file.variables[\"MG2IN_NAAI\"]\n",
    "npccn = file.variables[\"MG2IN_NPCCN\"]\n",
    "rndst = np.empty((t.shape[0], t.shape[1], t.shape[2], 4))\n",
    "rndst[:,:,:,0] = file.variables[\"MG2IN_RNDST1\"][:]\n",
    "rndst[:,:,:,1] = file.variables[\"MG2IN_RNDST2\"][:]\n",
    "rndst[:,:,:,2] = file.variables[\"MG2IN_RNDST3\"][:]\n",
    "rndst[:,:,:,3] = file.variables[\"MG2IN_RNDST4\"][:]\n",
    "nacon = np.empty((t.shape[0], t.shape[1], t.shape[2], 4))\n",
    "nacon[:,:,:,0] = file.variables[\"MG2IN_NACON1\"][:]\n",
    "nacon[:,:,:,1] = file.variables[\"MG2IN_NACON2\"][:]\n",
    "nacon[:,:,:,2] = file.variables[\"MG2IN_NACON3\"][:]\n",
    "nacon[:,:,:,3] = file.variables[\"MG2IN_NACON4\"][:]\n",
    "frzimm = file.variables[\"MG2IN_FRZIMM\"]\n",
    "frzcnt = file.variables[\"MG2IN_FRZCNT\"]\n",
    "frzdep = file.variables[\"MG2IN_FRZDEP\"]\n",
    "\n",
    "t_loc = np.empty((mgncol, t.shape[1]), order='F')\n",
    "q_loc = np.empty((mgncol, q.shape[1]), order='F')\n",
    "qc_loc = np.empty((mgncol, qc.shape[1]), order='F')\n",
    "qi_loc = np.empty((mgncol, qi.shape[1]), order='F')\n",
    "nc_loc = np.empty((mgncol, nc.shape[1]), order='F')\n",
    "ni_loc = np.empty((mgncol, ni.shape[1]), order='F')\n",
    "qr_loc = np.empty((mgncol, qr.shape[1]), order='F')\n",
    "qs_loc = np.empty((mgncol, qs.shape[1]), order='F')\n",
    "nr_loc = np.empty((mgncol, nr.shape[1]), order='F')\n",
    "ns_loc = np.empty((mgncol, ns.shape[1]), order='F')\n",
    "relvar_loc = np.empty((mgncol, relvar.shape[1]), order='F')\n",
    "accre_enhan_loc = np.empty((mgncol, accre_enhan.shape[1]), order='F')\n",
    "p_loc = np.empty((mgncol, p.shape[1]), order='F')\n",
    "pdel_loc = np.empty((mgncol, pdel.shape[1]), order='F')\n",
    "precipf_loc = np.empty((mgncol, precipf.shape[1]), order='F')\n",
    "liqcldf_loc = np.empty((mgncol, liqcldf.shape[1]), order='F')\n",
    "icecldf_loc = np.empty((mgncol, icecldf.shape[1]), order='F')\n",
    "naai_loc = np.empty((mgncol, naai.shape[1]), order='F')\n",
    "npccn_loc = np.empty((mgncol, npccn.shape[1]), order='F')\n",
    "rndst_loc = np.empty((mgncol, rndst.shape[1], 4), order='F')\n",
    "nacon_loc = np.empty((mgncol, nacon.shape[1], 4), order='F')\n",
    "frzimm_loc = np.empty((mgncol, frzimm.shape[1]), order='F')\n",
    "frzcnt_loc = np.empty((mgncol, frzcnt.shape[1]), order='F')\n",
    "frzdep_loc = np.empty((mgncol, frzdep.shape[1]), order='F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop\n",
    "\n",
    "This loop runs MG2 on a designated number of columns using a range of time step sizes, and creates the data arrays that will be plotted (or otherwise used). At the end of the run, the 2-norm estimate of error for each column will be placed in the `norms` variable, which is a dictionary indexed by variable name, containing arrays of estimated errors at particular columns and timestep sizes.\n",
    "\n",
    "For instance, the 2-norm of error in variable `Q`, in column `c`, for the `i+1`-th timestep in the `timesteps` array, will be located at `norms['Q'][c,i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Total number of columns to use in plots.\n",
    "total_columns = 256\n",
    "# Time in seconds of run.\n",
    "final_time = 300.\n",
    "# Timesteps to run out (the data points in the plot).\n",
    "# Must divide final_time exactly (currently not tolerant of floating-point error).\n",
    "timesteps = np.array([0.25, 1., 2., 5., 10., 15., 30., 60., 75., 100., 150., 300.])\n",
    "\n",
    "# Check (annoying) limitation on mgncol.\n",
    "assert total_columns % mgncol == 0, \\\n",
    "        \"total columns ({}) does not divide MG2 batch size ({})\".format(total_columns, mgncol)\n",
    "\n",
    "# Check to make sure timestep sizes are valid before entering loop.\n",
    "for it in range(timesteps.size):\n",
    "    assert final_time % timesteps[it] == 0., \\\n",
    "        \"timestep ({}) does not divide final time ({})\".format(timesteps[it], final_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_arrays = {\n",
    "    'T': t_loc,\n",
    "    'Q': q_loc,\n",
    "    'QC': qc_loc,\n",
    "    'QI': qi_loc,\n",
    "    'QR': qr_loc,\n",
    "    'QS': qs_loc,\n",
    "}\n",
    "var_names = sorted(list(loc_arrays.keys()))\n",
    "norms = {}\n",
    "finals = {}\n",
    "for name in var_names:\n",
    "    norms[name] = np.zeros((total_columns, timesteps.size - 1))\n",
    "    finals[name] = np.zeros((total_columns, lev))\n",
    "\n",
    "for it in range(timesteps.size):\n",
    "    print(\"Starting timestep=\", timesteps[it])\n",
    "    nsteps = int(round(final_time / timesteps[it]))\n",
    "    deltat = float(timesteps[it])\n",
    "\n",
    "    for offset in range(total_columns // mgncol):\n",
    "        t_loc[:,:] = t[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        q_loc[:,:] = q[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        qc_loc[:,:] = qc[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        qi_loc[:,:] = qi[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        nc_loc[:,:] = nc[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        ni_loc[:,:] = ni[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        qr_loc[:,:] = qr[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        qs_loc[:,:] = qs[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        nr_loc[:,:] = nr[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        ns_loc[:,:] = ns[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        relvar_loc[:,:] = relvar[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        accre_enhan_loc[:,:] = accre_enhan[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        p_loc[:,:] = p[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        pdel_loc[:,:] = pdel[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        precipf_loc[:,:] = precipf[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        liqcldf_loc[:,:] = liqcldf[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        icecldf_loc[:,:] = icecldf[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        naai_loc[:,:] = naai[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        npccn_loc[:,:] = npccn[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        rndst_loc[:,:,:] = rndst[0,:,offset*mgncol:(offset+1)*mgncol,:].transpose([1, 0, 2])\n",
    "        nacon_loc[:,:,:] = nacon[0,:,offset*mgncol:(offset+1)*mgncol,:].transpose([1, 0, 2])\n",
    "        frzimm_loc[:,:] = frzimm[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        frzcnt_loc[:,:] = frzcnt[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "        frzdep_loc[:,:] = frzdep[0,:,offset*mgncol:(offset+1)*mgncol].transpose()\n",
    "\n",
    "        for n in range(nsteps):\n",
    "            qcsinksum_rate1ord, tlat, qvlat, qctend, qitend, nctend, nitend, qrtend, \\\n",
    "                qstend, nrtend, nstend, effc, effc_fn, effi, prect, preci, nevapr, \\\n",
    "                evapsnow, prain, prodsnow, cmeout, deffi, pgamrad, lamcrad, qsout, dsout, \\\n",
    "                rflx, sflx, qrout, reff_rain, reff_snow, qcsevap, qisevap, qvres, cmeitot, \\\n",
    "                vtrmc, vtrmi, umr, ums, qcsedten, qisedten, qrsedten, qssedten, pratot, \\\n",
    "                prctot, mnuccctot, mnuccttot, msacwitot, psacwstot, bergstot, bergtot, \\\n",
    "                melttot, homotot, qcrestot, prcitot, praitot, qirestot, mnuccrtot, \\\n",
    "                pracstot, meltsdttot, frzrdttot, mnuccdtot, nrout, nsout, refl, arefl, \\\n",
    "                areflz, frefl, csrfl, acsrfl, fcsrfl, rercld, ncai, ncal, qrout2, qsout2, \\\n",
    "                nrout2, nsout2, drout2, dsout2, freqs, freqr, nfice, qcrat, errstring, \\\n",
    "                prer_evap \\\n",
    "                = mg.micro_mg_tend(deltat, t_loc, q_loc, qc_loc, qi_loc, nc_loc,\n",
    "                                   ni_loc, qr_loc, qs_loc, nr_loc, ns_loc,\n",
    "                                   relvar_loc, accre_enhan_loc, p_loc, pdel_loc,\n",
    "                                   precipf_loc, liqcldf_loc, icecldf_loc, naai_loc,\n",
    "                                   npccn_loc, rndst_loc, nacon_loc,\n",
    "                                   frzimm=frzimm_loc, frzcnt=frzcnt_loc,\n",
    "                                   frzdep=frzdep_loc, mgncol=mgncol, nlev=lev)\n",
    "\n",
    "            # Should use geopotential!\n",
    "            t_loc += tlat * deltat / cpair\n",
    "            q_loc += qvlat * deltat\n",
    "            q_loc[:,:] = np.where(q_loc < 1.e-12, 1.e-12, q_loc)\n",
    "            qc_loc += qctend * deltat\n",
    "            qc_loc[:,:] = np.where(qc_loc < 0., 0., qc_loc)\n",
    "            qi_loc += qitend * deltat\n",
    "            qi_loc[:,:] = np.where(qi_loc < 0., 0., qi_loc)\n",
    "            qr_loc += qrtend * deltat\n",
    "            qr_loc[:,:] = np.where(qr_loc < 0., 0., qr_loc)\n",
    "            qs_loc += qstend * deltat\n",
    "            qs_loc[:,:] = np.where(qs_loc < 0., 0., qs_loc)\n",
    "            nc_loc += nctend * deltat\n",
    "            nc_loc[:,:] = np.where(nc_loc > 1.e10, 1.e10, np.where(nc_loc < 1.e-12, 1.e-12, nc_loc))\n",
    "            ni_loc += nitend * deltat\n",
    "            ni_loc[:,:] = np.where(nc_loc > 1.e10, 1.e10, np.where(ni_loc < 1.e-12, 1.e-12, ni_loc))\n",
    "            nr_loc += nrtend * deltat\n",
    "            nr_loc[:,:] = np.where(nc_loc > 1.e10, 1.e10, np.where(nr_loc < 1.e-12, 1.e-12, nr_loc))\n",
    "            ns_loc += nstend * deltat\n",
    "            ns_loc[:,:] = np.where(nc_loc > 1.e10, 1.e10, np.where(ns_loc < 1.e-12, 1.e-12, ns_loc))\n",
    "\n",
    "        if it == 0:\n",
    "            for name in var_names:\n",
    "                finals[name][offset*mgncol:(offset+1)*mgncol,:] = loc_arrays[name]\n",
    "        else:\n",
    "            for name in var_names:\n",
    "                norms[name][offset*mgncol:(offset+1)*mgncol,it-1] \\\n",
    "                    = la.norm(finals[name][offset*mgncol:(offset+1)*mgncol,:] - loc_arrays[name],\n",
    "                              axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Convergence Plots\n",
    "\n",
    "This function provides the ability to track the convergence of a particular variable. In order to do this, we need to collapse the vector of errors across all columns into a single number. This is done by finding the error at a given percentile (e.g. the 50th percentile is the median error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_variable_convergence(name, percentiles, estimate_slopes=True):\n",
    "    \"\"\"Create a convergence plot for a given variable.\n",
    "\n",
    "    Inputs:\n",
    "    name - Variable name (must be one of the keys of loc_arrays).\n",
    "    percentiles - Percentiles of error to plot (e.g. 50. is the median).\n",
    "    estimate_slopes - Print out an estimated slope for each percentile.\n",
    "    \"\"\"\n",
    "    for p in percentiles:\n",
    "        norms_p = np.percentile(norms[name], p, axis=0)\n",
    "        plt.loglog(timesteps[1:], norms_p, label='Percentile={:.1f}'.format(p))\n",
    "        if estimate_slopes:\n",
    "            coefs = np.polyfit(np.log(timesteps[1:]), np.log(norms_p), 1)\n",
    "            print(\"Estimated slope for percentile {:.1f} is {}.\".format(p, coefs[0]))\n",
    "    plt.xlabel('Seconds/timestep')\n",
    "    plt.ylabel('Norm of difference in {} from $\\Delta$t={}'.format(name, timesteps[0]))\n",
    "    plt.legend(loc='best')\n",
    "    plt.axis('tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_variable_convergence(\"QR\", (100., 90., 50.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column-tracking Convergence Plots\n",
    "\n",
    "Rather than tracking errors at a given percentile in each timestep, we can instead use percentiles to find a set of columns at *one* timestep, and then produce convergence plots specific to that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_column_variable_convergence(name, percentiles, timestep, estimate_slopes=True):\n",
    "    \"\"\"Create a convergence plot for a given variable, tracking particular columns.\n",
    "\n",
    "    Inputs:\n",
    "    name - Variable name (must be one of the keys of loc_arrays).\n",
    "    percentiles - Percentiles of error to plot (e.g. 50. is the median).\n",
    "    timestep - Which timestep to evaluate the percentiles at (must be in the \"timesteps\" list).\n",
    "    estimate_slopes - Print out an estimated slope for each column.\n",
    "    \"\"\"\n",
    "    indices = np.argsort(norms[name][:,list(timesteps).index(timestep)-1])\n",
    "    for p in percentiles:\n",
    "        norms_p = norms[name][indices[round(p/100.*(total_columns-1))]]\n",
    "        plt.loglog(timesteps[1:], norms_p, label='Percentile={:.1f}'.format(p))\n",
    "        if estimate_slopes:\n",
    "            coefs = np.polyfit(np.log(timesteps[1:]), np.log(norms_p), 1)\n",
    "            print(\"Estimated slope for percentile {:.1f} is {}.\".format(p, coefs[0]))\n",
    "    plt.xlabel('Seconds/timestep')\n",
    "    plt.ylabel('Norm of difference in {} from $\\Delta$t={}'.format(name, timesteps[0]))\n",
    "    plt.legend(loc='best')\n",
    "    plt.axis('tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_column_variable_convergence(\"QR\", (100., 90., 50.), 5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_column_variable_convergence(\"QR\", (100., 90., 50.), 100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
